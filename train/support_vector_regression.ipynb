{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data_clean/filtered_dataset.csv')  # Update the path if needed\n",
    "\n",
    "# Target column\n",
    "target_column = 'AQI'\n",
    "\n",
    "# Step 1: Feature Engineering on Date and Time\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Hour'] = pd.to_datetime(df['Time'], format='%H:%M:%S', errors='coerce').dt.hour\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Weekday'] = df['Date'].dt.weekday\n",
    "\n",
    "# Drop original 'Date' and 'Time'\n",
    "df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "\n",
    "# Step 2: One-Hot Encoding for AQI_Bucket\n",
    "df = pd.get_dummies(df, columns=['AQI_Bucket'], drop_first=True)\n",
    "\n",
    "# Step 3: Split Features and Target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Step 4: Define categorical and numerical columns\n",
    "categorical_cols = ['City']\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in categorical_cols]\n",
    "\n",
    "# Step 5: Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    "    stratify=y if y.nunique() < 2 else None\n",
    ")\n",
    "\n",
    "# Step 7: Apply transformations\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)\n",
    "\n",
    "# Step 8: Train the SVR model\n",
    "model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 10: Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n🔍 SVR Evaluation Metrics:\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"MSE:  {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²:   {r2:.2f}\")\n",
    "\n",
    "# Step 11: Plot error distribution\n",
    "errors = y_test - y_pred\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(errors, kde=True, bins=30, color='darkcyan')\n",
    "plt.title(\"Prediction Error Distribution (SVR)\")\n",
    "plt.xlabel(\"Error (Actual - Predicted AQI)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Save the model and pipeline\n",
    "joblib.dump(model, 'svr_model.pkl')\n",
    "joblib.dump(pipeline, 'preprocessing_pipeline_svr.pkl')\n",
    "print(\"\\n✅ SVR model and preprocessing pipeline saved as 'svr_model.pkl' and 'preprocessing_pipeline.pkl'\")\n",
    "\n",
    "# Step 13: Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.4, color='green', label=\"SVR Predictions\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Ideal Fit\")\n",
    "plt.xlabel(\"Actual AQI\")\n",
    "plt.ylabel(\"Predicted AQI\")\n",
    "plt.title(\"Actual vs Predicted AQI (SVR)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
